{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Resnet101.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBBr7ViDm5-p",
        "outputId": "315bd41d-b934-473b-e317-0840566bef78"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkiavSDTnSph",
        "outputId": "16701d77-99fb-4622-f903-aeea46772c41"
      },
      "source": [
        "%cd gdrive/My Drive/dvl"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/dvl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_A8lNBhnrd4",
        "outputId": "3704d4d6-a592-4bed-bf9e-0cd43d29ab05"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Mask_RCNN' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdL47pMuoBdp",
        "outputId": "18608dbf-8271-45fa-a1e5-a8956e818cc8"
      },
      "source": [
        "cd Mask_RCNN"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/dvl/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S98Z2yGh2fXv",
        "outputId": "6de42930-2529-4e2c-b1f7-718ff7bf16d6"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'drive': Transport endpoint is not connected\n",
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umac7AEhoD8U",
        "outputId": "b161e2cc-5f72-4861-9080-6177db3e175f"
      },
      "source": [
        "! python setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating mask_rcnn.egg-info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/mrcnn\n",
            "copying mrcnn/__init__.py -> build/lib/mrcnn\n",
            "copying mrcnn/config.py -> build/lib/mrcnn\n",
            "copying mrcnn/model.py -> build/lib/mrcnn\n",
            "copying mrcnn/parallel_model.py -> build/lib/mrcnn\n",
            "copying mrcnn/utils.py -> build/lib/mrcnn\n",
            "copying mrcnn/visualize.py -> build/lib/mrcnn\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.6.egg\n",
            "Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding mask-rcnn 2.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sQWSwk3oJX6",
        "outputId": "6eac8fd1-1165-4e77-a91c-71b8730e0f9f"
      },
      "source": [
        "!pip install segments-ai --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segments-ai\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/de/735c2061afa9c6bc75acf6637acf775589659e138ffe500fc0efa737263b/segments-ai-0.22.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from segments-ai) (1.19.4)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from segments-ai) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pycocotools in /usr/local/lib/python3.6/dist-packages (from segments-ai) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from segments-ai) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from segments-ai) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->segments-ai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->segments-ai) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->segments-ai) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->segments-ai) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->segments-ai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->segments-ai) (51.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools->segments-ai) (0.29.21)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools->segments-ai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools->segments-ai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools->segments-ai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools->segments-ai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools->segments-ai) (1.15.0)\n",
            "Building wheels for collected packages: segments-ai\n",
            "  Building wheel for segments-ai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segments-ai: filename=segments_ai-0.22-cp36-none-any.whl size=7608 sha256=5406d34b133a008e371047cff3bb2ea3168fefdde8d435f307672a5cf36e7222\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/7b/95/a090d57c52317b0e59cad83bbfd65beff11d37b4288b4860b6\n",
            "Successfully built segments-ai\n",
            "Installing collected packages: segments-ai\n",
            "Successfully installed segments-ai-0.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBRcKCq0huPK",
        "outputId": "94efb1c8-8841-42c8-9645-9caf2f1b6732"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "import tensorflow\r\n",
        "print(tensorflow.__version__)\r\n",
        "!pip install keras==2.1.5"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "Requirement already satisfied: keras==2.1.5 in /usr/local/lib/python3.6/dist-packages (2.1.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.19.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19JSMor1oQdY"
      },
      "source": [
        "\r\n",
        "import matplotlib\r\n",
        "# Agg backend runs without a display\r\n",
        "#matplotlib.use('Agg')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import os\r\n",
        "import sys\r\n",
        "import json\r\n",
        "import datetime\r\n",
        "import numpy as np\r\n",
        "import skimage.io\r\n",
        "from imgaug import augmenters as iaa\r\n",
        "\r\n",
        "# Root directory of the project\r\n",
        "ROOT_DIR = os.path.abspath(\"../\")\r\n",
        "\r\n",
        "# Import Mask RCNN\r\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\r\n",
        "from mrcnn.config import Config\r\n",
        "from mrcnn import utils\r\n",
        "from mrcnn import model as modellib\r\n",
        "from mrcnn import visualize\r\n",
        "\r\n",
        "# Path to trained weights file\r\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\r\n",
        "\r\n",
        "# Directory to save logs and model checkpoints, if not provided\r\n",
        "# through the command line argument --logs\r\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\r\n",
        "\r\n",
        "# Results directory\r\n",
        "# Save submission files here\r\n",
        "RESULTS_DIR = os.path.join(ROOT_DIR, \"results/\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J1wliLrpF9R"
      },
      "source": [
        "############################################################\r\n",
        "#  Configurations\r\n",
        "############################################################\r\n",
        "\r\n",
        "class BasilConfig(Config):\r\n",
        "    \"\"\"Configuration for training on the nucleus segmentation dataset.\"\"\"\r\n",
        "    # Give the configuration a recognizable name\r\n",
        "    NAME = \"basil\"\r\n",
        "\r\n",
        "    # Adjust depending on your GPU memory\r\n",
        "    IMAGES_PER_GPU = 6\r\n",
        "\r\n",
        "    # Number of classes (including background)\r\n",
        "    NUM_CLASSES = 1 + 1  # Background + leaf\r\n",
        "\r\n",
        "    # Number of training and validation steps per epoch\r\n",
        "    STEPS_PER_EPOCH = 131\r\n",
        "    #VALIDATION_STEPS = max(1, len(VAL_IMAGE_IDS) // IMAGES_PER_GPU)\r\n",
        "\r\n",
        "    # Don't exclude based on confidence. Since we have two classes\r\n",
        "    # then 0.5 is the minimum anyway as it picks between nucleus and BG\r\n",
        "    DETECTION_MIN_CONFIDENCE = 0.5\r\n",
        "\r\n",
        "    # Backbone network architecture\r\n",
        "    # Supported values are: resnet50, resnet101\r\n",
        "    BACKBONE = \"resnet50\"\r\n",
        "\r\n",
        "    # Input image resizing\r\n",
        "    # Random crops of size 512x512\r\n",
        "    # IMAGE_RESIZE_MODE = \"crop\"\r\n",
        "    # IMAGE_MIN_DIM = 256\r\n",
        "    # IMAGE_MAX_DIM = 256\r\n",
        "    # IMAGE_MIN_SCALE = 12.0\r\n",
        "\r\n",
        "    # Length of square anchor side in pixels\r\n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\r\n",
        "\r\n",
        "    # ROIs kept after non-maximum supression (training and inference)\r\n",
        "    POST_NMS_ROIS_TRAINING = 1000\r\n",
        "    POST_NMS_ROIS_INFERENCE = 2000\r\n",
        "\r\n",
        "    # Non-max suppression threshold to filter RPN proposals.\r\n",
        "    # You can increase this during training to generate more propsals.\r\n",
        "    RPN_NMS_THRESHOLD = 0.9\r\n",
        "\r\n",
        "    # How many anchors per image to use for RPN training\r\n",
        "    RPN_TRAIN_ANCHORS_PER_IMAGE = 64\r\n",
        "\r\n",
        "    # Image mean (RGB)\r\n",
        "    MEAN_PIXEL = np.array([43.53, 39.56, 48.22])\r\n",
        "\r\n",
        "    # If enabled, resizes instance masks to a smaller size to reduce\r\n",
        "    # memory load. Recommended when using high-resolution images.\r\n",
        "    USE_MINI_MASK = True\r\n",
        "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\r\n",
        "\r\n",
        "    # Number of ROIs per image to feed to classifier/mask heads\r\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\r\n",
        "    # enough positive proposals to fill this and keep a positive:negative\r\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\r\n",
        "    # the RPN NMS threshold.\r\n",
        "    TRAIN_ROIS_PER_IMAGE = 128\r\n",
        "\r\n",
        "    # Maximum number of ground truth instances to use in one image\r\n",
        "    MAX_GT_INSTANCES = 200\r\n",
        "\r\n",
        "    # Max number of final detections per image\r\n",
        "    DETECTION_MAX_INSTANCES = 400\r\n",
        "\r\n",
        "\r\n",
        "class BasilInferenceConfig(BasilConfig):\r\n",
        "    # Set batch size to 1 to run one image at a time\r\n",
        "    GPU_COUNT = 1\r\n",
        "    IMAGES_PER_GPU = 1\r\n",
        "    # Don't resize imager for inferencing\r\n",
        "    IMAGE_RESIZE_MODE = \"pad64\"\r\n",
        "    # Non-max suppression threshold to filter RPN proposals.\r\n",
        "    # You can increase this during training to generate more propsals.\r\n",
        "    RPN_NMS_THRESHOLD = 0.7\r\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fslC5_-UpN_C"
      },
      "source": [
        "############################################################\r\n",
        "#  Dataset\r\n",
        "############################################################\r\n",
        "\r\n",
        "class BasilDataset(utils.Dataset):\r\n",
        "  \r\n",
        "    def load_basil(self, dataset_dir, subset):\r\n",
        "        \"\"\"Load a subset of the nuclei dataset.\r\n",
        "        dataset_dir: Root directory of the dataset\r\n",
        "        subset: Subset to load. Either the name of the sub-directory,\r\n",
        "                such as stage1_train, stage1_test, ...etc. or, one of:\r\n",
        "                * train: stage1_train excluding validation images\r\n",
        "                * val: validation images from VAL_IMAGE_IDS\r\n",
        "        \"\"\"\r\n",
        "        # Add classes. We have one class.\r\n",
        "        # Naming the dataset nucleus, and the class nucleus\r\n",
        "        self.add_class(\"leaf\", 1, \"leaf\")\r\n",
        "\r\n",
        "        # Which subset?\r\n",
        "        # \"val\": use hard-coded list above\r\n",
        "        # \"train\": use data from stage1_train minus the hard-coded list above\r\n",
        "        # else: use the data from the specified sub-directory\r\n",
        "        assert subset in [\"train\", \"val\", \"stage1_train\", \"stage1_test\", \"stage2_test\"]\r\n",
        "        subset_dir = \"train\" if subset in [\"train\", \"val\"] else subset\r\n",
        "\r\n",
        "        \r\n",
        "        if subset == \"val\":\r\n",
        "            image_ids = [x.replace('.png', '') for x in os.listdir(os.path.join(dataset_dir,subset_dir)) if '_label_ground-truth' not in x]\r\n",
        "        else:\r\n",
        "            if subset == \"train\":\r\n",
        "                image_ids = [x.replace('.png', '') for x in os.listdir(os.path.join(dataset_dir,subset_dir)) if '_label_ground-truth' not in x]\r\n",
        "\r\n",
        "        # Add images\r\n",
        "        for image_id in image_ids:\r\n",
        "            self.add_image(\r\n",
        "                \"basil\",\r\n",
        "                image_id=image_id,\r\n",
        "                path=os.path.join(dataset_dir, subset_dir, \"{}.png\".format(image_id)))\r\n",
        "\r\n",
        "\r\n",
        "    def load_mask(self, image_id):\r\n",
        "        \"\"\"Generate instance masks for an image.\r\n",
        "        Returns:\r\n",
        "        masks: A bool array of shape [height, width, instance count] with\r\n",
        "        one mask per instance.\r\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\r\n",
        "        \"\"\"\r\n",
        "        info = self.image_info[image_id]\r\n",
        "\r\n",
        "        # get image\r\n",
        "\r\n",
        "        mask_img_path =  info['path'].replace('.png', '_label_ground-truth.png') \r\n",
        "\r\n",
        "        mask = skimage.io.imread(mask_img_path).astype(np.bool)\r\n",
        "\r\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\r\n",
        "        # one class ID, we return an array of ones\r\n",
        "        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\r\n",
        "\r\n",
        "    def image_reference(self, image_id):\r\n",
        "        \"\"\"Return the path of the image.\"\"\"\r\n",
        "        info = self.image_info[image_id]\r\n",
        "        if info[\"source\"] == \"leaf\":\r\n",
        "            return info[\"id\"]\r\n",
        "        else:\r\n",
        "            super(self.__class__, self).image_reference(image_id)\r\n",
        "\r\n",
        "\r\n",
        "   "
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-gF8lDjp3PV"
      },
      "source": [
        "############################################################\r\n",
        "#  Training\r\n",
        "############################################################\r\n",
        "\r\n",
        "def train(model, dataset_dir, subset):\r\n",
        "    \"\"\"Train the model.\"\"\"\r\n",
        "    # Training dataset.\r\n",
        "    dataset_train = BasilDataset()\r\n",
        "    dataset_train.load_basil(dataset_dir, subset)\r\n",
        "    dataset_train.prepare()\r\n",
        "\r\n",
        "    # Validation dataset\r\n",
        "    dataset_val = BasilDataset()\r\n",
        "    dataset_val.load_basil(dataset_dir, \"val\")\r\n",
        "    dataset_val.prepare()\r\n",
        "\r\n",
        "    # Image augmentation\r\n",
        "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\r\n",
        "    augmentation = iaa.SomeOf((0, 2), [\r\n",
        "        iaa.Fliplr(0.5),\r\n",
        "        iaa.Flipud(0.5),\r\n",
        "        iaa.OneOf([iaa.Affine(rotate=90),\r\n",
        "                   iaa.Affine(rotate=180),\r\n",
        "                   iaa.Affine(rotate=270)]),\r\n",
        "        iaa.Multiply((0.8, 1.5)),\r\n",
        "        iaa.GaussianBlur(sigma=(0.0, 5.0))\r\n",
        "    ])\r\n",
        "\r\n",
        "    # *** This training schedule is an example. Update to your needs ***\r\n",
        "\r\n",
        "    # If starting from imagenet, train heads only for a bit\r\n",
        "    # since they have random weights\r\n",
        "    print(\"Train network heads\")\r\n",
        "    model.train(dataset_train, dataset_val,\r\n",
        "                learning_rate=config.LEARNING_RATE,\r\n",
        "                epochs=20,\r\n",
        "                augmentation=augmentation,\r\n",
        "                layers='heads')\r\n",
        "\r\n",
        "    print(\"Train all layers\")\r\n",
        "    model.train(dataset_train, dataset_val,\r\n",
        "                learning_rate=config.LEARNING_RATE,\r\n",
        "                epochs=40,\r\n",
        "                augmentation=augmentation,\r\n",
        "                layers='all')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNwPOk6TRdbw"
      },
      "source": [
        "############################################################\r\n",
        "#  RLE Encoding\r\n",
        "############################################################\r\n",
        "\r\n",
        "def rle_encode(mask):\r\n",
        "    \"\"\"Encodes a mask in Run Length Encoding (RLE).\r\n",
        "    Returns a string of space-separated values.\r\n",
        "    \"\"\"\r\n",
        "    assert mask.ndim == 2, \"Mask must be of shape [Height, Width]\"\r\n",
        "    # Flatten it column wise\r\n",
        "    m = mask.T.flatten()\r\n",
        "    # Compute gradient. Equals 1 or -1 at transition points\r\n",
        "    g = np.diff(np.concatenate([[0], m, [0]]), n=1)\r\n",
        "    # 1-based indicies of transition points (where gradient != 0)\r\n",
        "    rle = np.where(g != 0)[0].reshape([-1, 2]) + 1\r\n",
        "    # Convert second index in each pair to lenth\r\n",
        "    rle[:, 1] = rle[:, 1] - rle[:, 0]\r\n",
        "    return \" \".join(map(str, rle.flatten()))\r\n",
        "\r\n",
        "\r\n",
        "def rle_decode(rle, shape):\r\n",
        "    \"\"\"Decodes an RLE encoded list of space separated\r\n",
        "    numbers and returns a binary mask.\"\"\"\r\n",
        "    rle = list(map(int, rle.split()))\r\n",
        "    rle = np.array(rle, dtype=np.int32).reshape([-1, 2])\r\n",
        "    rle[:, 1] += rle[:, 0]\r\n",
        "    rle -= 1\r\n",
        "    mask = np.zeros([shape[0] * shape[1]], np.bool)\r\n",
        "    for s, e in rle:\r\n",
        "        assert 0 <= s < mask.shape[0]\r\n",
        "        assert 1 <= e <= mask.shape[0], \"shape: {}  s {}  e {}\".format(shape, s, e)\r\n",
        "        mask[s:e] = 1\r\n",
        "    # Reshape and transpose\r\n",
        "    mask = mask.reshape([shape[1], shape[0]]).T\r\n",
        "    return mask\r\n",
        "\r\n",
        "\r\n",
        "def mask_to_rle(image_id, mask, scores):\r\n",
        "    \"Encodes instance masks to submission format.\"\r\n",
        "    assert mask.ndim == 3, \"Mask must be [H, W, count]\"\r\n",
        "    # If mask is empty, return line with image ID only\r\n",
        "    if mask.shape[-1] == 0:\r\n",
        "        return \"{},\".format(image_id)\r\n",
        "    # Remove mask overlaps\r\n",
        "    # Multiply each instance mask by its score order\r\n",
        "    # then take the maximum across the last dimension\r\n",
        "    order = np.argsort(scores)[::-1] + 1  # 1-based descending\r\n",
        "    mask = np.max(mask * np.reshape(order, [1, 1, -1]), -1)\r\n",
        "    # Loop over instance masks\r\n",
        "    lines = []\r\n",
        "    for o in order:\r\n",
        "        m = np.where(mask == o, 1, 0)\r\n",
        "        # Skip if empty\r\n",
        "        if m.sum() == 0.0:\r\n",
        "            continue\r\n",
        "        rle = rle_encode(m)\r\n",
        "        lines.append(\"{}, {}\".format(image_id, rle))\r\n",
        "    return \"\\n\".join(lines)\r\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L6yW_ALRex2"
      },
      "source": [
        "############################################################\r\n",
        "#  Detection\r\n",
        "############################################################\r\n",
        "\r\n",
        "def detect(model, dataset_dir, subset):\r\n",
        "    \"\"\"Run detection on images in the given directory.\"\"\"\r\n",
        "    print(\"Running on {}\".format(dataset_dir))\r\n",
        "\r\n",
        "    # Create directory\r\n",
        "    if not os.path.exists(RESULTS_DIR):\r\n",
        "        os.makedirs(RESULTS_DIR)\r\n",
        "    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\r\n",
        "    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\r\n",
        "    os.makedirs(submit_dir)\r\n",
        "\r\n",
        "    # Read dataset\r\n",
        "    dataset = BasilDataset()\r\n",
        "    dataset.load_basil(dataset_dir, subset)\r\n",
        "    dataset.prepare()\r\n",
        "    # Load over images\r\n",
        "    submission = []\r\n",
        "    for image_id in dataset.image_ids:\r\n",
        "        # Load image and run detection\r\n",
        "        image = dataset.load_image(image_id)\r\n",
        "        # Detect objects\r\n",
        "        r = model.detect([image], verbose=0)[0]\r\n",
        "        # Encode image to RLE. Returns a string of multiple lines\r\n",
        "        source_id = dataset.image_info[image_id][\"id\"]\r\n",
        "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\r\n",
        "        submission.append(rle)\r\n",
        "        # Save image with masks\r\n",
        "        visualize.display_instances(\r\n",
        "            image, r['rois'], r['masks'], r['class_ids'],\r\n",
        "            dataset.class_names, r['scores'],\r\n",
        "            show_bbox=False, show_mask=False,\r\n",
        "            title=\"Predictions\")\r\n",
        "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\r\n",
        "\r\n",
        "    # Save to csv file\r\n",
        "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\r\n",
        "    file_path = os.path.join(submit_dir, \"submit.csv\")\r\n",
        "    with open(file_path, \"w\") as f:\r\n",
        "        f.write(submission)\r\n",
        "    print(\"Saved to \", submit_dir)\r\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE0_dcCEfjUk",
        "outputId": "f8e47fd7-473f-4a47-d0f8-494a83fec5ef"
      },
      "source": [
        "############################################################\r\n",
        "#  Command Line\r\n",
        "############################################################\r\n",
        "\r\n",
        "   \r\n",
        "\r\n",
        "# Configurations\r\n",
        "config = BasilConfig()\r\n",
        "config.display()\r\n",
        "\r\n",
        "# Create model\r\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir= 'DEFAULT_LOGS_DIR')\r\n",
        "\r\n",
        "\r\n",
        "# Select weights file to load\r\n",
        "weights_path = COCO_WEIGHTS_PATH\r\n",
        "# elif args.weights.lower() == \"last\":\r\n",
        "#     # Find last trained weights\r\n",
        "#     weights_path = model.find_last()\r\n",
        "# elif args.weights.lower() == \"imagenet\":\r\n",
        "#     # Start from ImageNet trained weights\r\n",
        "#     weights_path = model.get_imagenet_weights()\r\n",
        "# else:\r\n",
        "#     weights_path = args.weights\r\n",
        "\r\n",
        "# Load weights\r\n",
        "print(\"Loading weights \", weights_path)\r\n",
        "    # Exclude the last layers because they require a matching\r\n",
        "    # number of classes\r\n",
        "model.load_weights(weights_path, by_name=True, exclude=[\r\n",
        "    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\r\n",
        "    \"mrcnn_bbox\", \"mrcnn_mask\"])\r\n",
        "\r\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet50\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     6\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        400\n",
            "DETECTION_MIN_CONFIDENCE       0.5\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 6\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               200\n",
            "MEAN_PIXEL                     [43.53 39.56 48.22]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           basil\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        2000\n",
            "POST_NMS_ROIS_TRAINING         1000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.9\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    64\n",
            "STEPS_PER_EPOCH                131\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           128\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "Loading weights  /content/gdrive/My Drive/dvl/mask_rcnn_coco.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Oxf8k0ZFIqjP",
        "outputId": "42c9199e-21f1-44ca-ec0a-f7d46c74f578"
      },
      "source": [
        "\r\n",
        "# Train or evaluate\r\n",
        "train(model, './../segments/kailkuhn_playground/pictures', 'train')\r\n",
        "\r\n",
        "    # detect(model, args.dataset, args.subset)\r\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train network heads\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: DEFAULT_LOGS_DIR/basil20201225T2301/mask_rcnn_basil_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Error processing image {'id': 'L_11_1', 'source': 'basil', 'path': './../segments/kailkuhn_playground/pictures/train/L_11_1.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rank\n",
            "ERROR:root:Error processing image {'id': 'L_11_2', 'source': 'basil', 'path': './../segments/kailkuhn_playground/pictures/train/L_11_2.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rankERROR:root:Error processing image {'id': 'L_11_2', 'source': 'basil', 'path': './../segments/kailkuhn_playground/pictures/train/L_11_2.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rank\n",
            "\n",
            "ERROR:root:Error processing image {'id': 'L_11_3', 'source': 'basil', 'path': './../segments/kailkuhn_playground/pictures/train/L_11_3.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rank\n",
            "ERROR:root:Error processing image {'id': 'L_11_3', 'source': 'basil', 'path': './../segments/kailkuhn_playground/pictures/train/L_11_3.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rank\n",
            "ERROR:root:Error processing image {'id': 'L_11_4', 'source': 'basil', 'path': './../segments/kailkuhn_playground/pictures/train/L_11_4.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rank\n",
            "ERROR:root:Error processing image {'id': 'L_11_4', 'source': 'basil', 'path': './../segments/kailkuhn_playground/pictures/train/L_11_4.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rank\n",
            "ERROR:root:Error processing image {'id': 'L_11_1', 'source': 'basil', 'path': './../segments/kailkuhn_playground/pictures/train/L_11_1.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rank\n",
            "ERROR:root:Error processing image {'id': 'L_11_1', 'source': 'basil', 'path': './../segments/kailkuhn_playground/pictures/train/L_11_1.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rank\n",
            "ERROR:root:Error processing image {'id': 'L_11_3', 'source': 'basil', 'path': './../segments/kailkuhn_playground/pictures/train/L_11_3.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rankERROR:root:Error processing image {'id': 'L_11_3', 'source': 'basil', 'path': './../segments/kailkuhn_playground/pictures/train/L_11_3.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rank\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 677, in _data_generator_task\n",
            "    generator_output = next(self._generator)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\", line 1220, in load_image_gt\n",
            "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
            "  File \"/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/utils.py\", line 508, in resize_mask\n",
            "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 601, in zoom\n",
            "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
            "    raise RuntimeError(err)\n",
            "RuntimeError: sequence argument must have length equal to input rank\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-7a281a6d893e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Train or evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./../segments/kailkuhn_playground/pictures'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# detect(model, args.dataset, args.subset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-0e3b65ea7f9f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset_dir, subset)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 layers='heads')\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train all layers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/dvl/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m         )\n\u001b[1;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: sequence argument must have length equal to input rank"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkvtwgLUphnB",
        "outputId": "3a0d1fbe-af7f-4920-9b89-2926a3e27f4d"
      },
      "source": [
        "test ='truth'\r\n",
        "\r\n",
        "os.listdir('./../segments/kailkuhn_playground/pictures/train')\r\n",
        "[x.replace('.png', '')  for x in os.listdir('./../segments/kailkuhn_playground/pictures/train') if 'truth' not in x]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['L_11_3', 'L_11_1', 'L_11_2', 'L_11_4']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    }
  ]
}